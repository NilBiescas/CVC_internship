Train Epoch: 0 	Batch_idx: 0 	Loss: 1.781132
Train Epoch: 0 	Batch_idx: 100 	Loss: 1.369894
Train Epoch: 0 	Batch_idx: 200 	Loss: 1.918322
Train Epoch: 0 	Batch_idx: 300 	Loss: 1.937932
Train Epoch: 0 	Batch_idx: 400 	Loss: 1.722186
Train Epoch: 0 	Batch_idx: 500 	Loss: 1.476293
Train Epoch: 0 	Batch_idx: 600 	Loss: 1.732320
Train Epoch: 0 	Batch_idx: 700 	Loss: 1.653812
Train Epoch: 0 	Batch_idx: 800 	Loss: 1.530577
Train Epoch: 0 	Batch_idx: 900 	Loss: 1.479103
Train Epoch: 0 	Batch_idx: 1000 	Loss: 1.548443
Train Epoch: 0 	Batch_idx: 1100 	Loss: 1.774289
Train Epoch: 0 	Batch_idx: 1200 	Loss: 1.577580
Train Epoch: 0 	Batch_idx: 1300 	Loss: 1.472458
Train Epoch: 0 	Batch_idx: 1400 	Loss: 1.700932
Train Epoch: 0 	Batch_idx: 1500 	Loss: 1.559420
Train Epoch: 0 	Batch_idx: 1600 	Loss: 1.347227
Train Epoch: 0 	Batch_idx: 1700 	Loss: 1.703277
Train Epoch: 0 	Batch_idx: 1800 	Loss: 1.474102
Train Epoch: 0 	Batch_idx: 1900 	Loss: 1.687580
Train Epoch: 0 	Batch_idx: 2000 	Loss: 1.450218
Train Epoch: 0 	Batch_idx: 2100 	Loss: 1.577706
Train Epoch: 0 	Batch_idx: 2200 	Loss: 1.641668
Train Epoch: 0 	Batch_idx: 2300 	Loss: 1.598898
Train Epoch: 0 	Batch_idx: 2400 	Loss: 1.543620
Train Epoch: 0 	Batch_idx: 2500 	Loss: 1.698789
Train Epoch: 0 	Batch_idx: 2600 	Loss: 1.515288
Train Epoch: 0 	Batch_idx: 2700 	Loss: 1.441173
Train Epoch: 0 	Batch_idx: 2800 	Loss: 1.458008
Train Epoch: 0 	Batch_idx: 2900 	Loss: 1.611329
Train Epoch: 0 	Batch_idx: 3000 	Loss: 1.708355
Train Epoch: 0 	Batch_idx: 3100 	Loss: 1.501681
Train Epoch: 0 	Batch_idx: 3200 	Loss: 1.633007
Train Epoch: 0 	Batch_idx: 3300 	Loss: 1.574072
Train Epoch: 0 	Batch_idx: 3400 	Loss: 1.760258
Train Epoch: 0 	Batch_idx: 3500 	Loss: 1.520882
Train Epoch: 0 	Batch_idx: 3600 	Loss: 1.570578
Train Epoch: 0 	Batch_idx: 3700 	Loss: 1.437934
Train Epoch: 0 	Batch_idx: 3800 	Loss: 1.912369
Train Epoch: 0 	Batch_idx: 3900 	Loss: 2.341702
Train Epoch: 0 	Batch_idx: 4000 	Loss: 1.624897
Train Epoch: 0 	Batch_idx: 4100 	Loss: 1.427487
Train Epoch: 0 	Batch_idx: 4200 	Loss: 1.510799
Train Epoch: 0 	Batch_idx: 4300 	Loss: 1.631017
Train Epoch: 0 	Batch_idx: 4400 	Loss: 1.617000
Traceback (most recent call last):
  File "/home/nbiescas/Desktop/CVC/CVC_internship/main.py", line 29, in <module>
    model_pipeline(model, train_loader, val_loader, test_loader)
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 99, in model_pipeline
    train_loss = train(epoch, criterion, model, optimizer, train_loader)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 76, in train
    loss.backward()
  File "/home/nbiescas/miniconda3/envs/CVC/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/nbiescas/miniconda3/envs/CVC/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt