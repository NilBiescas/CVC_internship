Traceback (most recent call last):
  File "/home/nbiescas/Desktop/CVC/CVC_internship/main.py", line 29, in <module>
    model_pipeline(model, train_loader, val_loader, test_loader)
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 92, in model_pipeline
    train_loss = train(epoch, criterion, model, optimizer, train_loader)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 69, in train
    loss = criterion(output, adj_matrix, model.mean, model.log_std) #Can it be a problem it the mean is computed in the batched graphs ?
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 16, in loss_VGAE
    loss =  F.binary_cross_entropy(output.view(-1), adj.view(-1))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nbiescas/miniconda3/envs/CVC/lib/python3.11/site-packages/torch/nn/functional.py", line 3098, in binary_cross_entropy
    return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.