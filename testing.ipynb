{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/nbiescas/Desktop/CVC/CVC_internship/omniglot.npz\"\n",
    "import numpy as np\n",
    "import random\n",
    "import webbrowser\n",
    "import time\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "load_data = np.load(filename, allow_pickle=True, encoding='latin1')\n",
    "\n",
    "\n",
    "train_set = load_data['train']\n",
    "valid_set = load_data['valid']\n",
    "test_set = load_data['test']\n",
    "\n",
    "def generate_grid():\n",
    "    url = r\"D:\\NIL\\OMNIGLOT\\sample.svg\"\n",
    "    for _ in range(5):\n",
    "        s_list = []\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                s_list.append((random.choice(train_set), (i, j)))\n",
    "\n",
    "        matrix = make_grid_svg(s_list=s_list)\n",
    "        draw_strokes(matrix)\n",
    "        webbrowser.open(url)\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "def read_npz_files(filename):\n",
    "    if (filename.split('.')[-1] != 'npz'):\n",
    "        raise ValueError(\"Invalid file format\")\n",
    "    load_data = np.load(filename, allow_pickle=True, encoding='latin1')\n",
    "    return load_data['train'], load_data['valid'], load_data['test']\n",
    "\n",
    "def read_letter(data, self_loops = True):\n",
    "    if self_loops:\n",
    "        adj_matrix = np.identity(len(data)) \n",
    "    else:\n",
    "        adj_matrix = np.zeros((len(data), len(data))) \n",
    "    node_feat  = np.zeros((len(data), 2)) # features (num_nodes x 2) 2 because the features are the cordinates of each node    \n",
    "    \n",
    "    x = 0\n",
    "    y = 0\n",
    "    for node_id, row in enumerate(data):\n",
    "        x += row[0]\n",
    "        y -= row[1]\n",
    "        node_feat[node_id] = [x, y]\n",
    "        if (node_id != 0):\n",
    "            _, _, previous_lift = data[node_id - 1]\n",
    "            if (previous_lift == 1):\n",
    "                continue\n",
    "            adj_matrix[node_id][node_id - 1] = 1\n",
    "            adj_matrix[node_id - 1][node_id] = 1\n",
    "\n",
    "    src, dst = np.nonzero(adj_matrix)\n",
    "    g = dgl.graph((src, dst))\n",
    "    g.ndata['feat'] = torch.from_numpy(node_feat)\n",
    "\n",
    "    #G = nx.from_numpy_array(am) # Createa a graph from an adjacency matrix\n",
    "    #nx.set_node_attributes(G, node_label, 'position')\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(G, position, ax):\n",
    "    #fig, ax = plt.subplots(figsize=(5, 7))\n",
    "      \n",
    "    # Draw nodes and edges\n",
    "    nx.draw_networkx_nodes(G, ax=ax, pos=position)\n",
    "    nx.draw_networkx_edges(G, ax=ax, pos=position)\n",
    "    \n",
    "    # Add labels\n",
    "    node_labels = {n: n for n in G.nodes()}\n",
    "    nx.draw_networkx_labels(G, ax=ax, pos=position, labels=node_labels)\n",
    "    \n",
    "    # Customize plot appearance\n",
    "    ax.set_title(\"Graph Visualization\")\n",
    "    ax.set_xlabel(\"X Axis\")\n",
    "    ax.set_ylabel(\"Y Axis\")\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_set[random.randint(0, len(train_set))]\n",
    "dgl_graph = read_letter(sample, self_loops = True)\n",
    "\n",
    "def random_remove_edges(dgl_graph, prob = 0.1):\n",
    "    num_edges = dgl_graph.num_edges()\n",
    "    edge_ids = list(range(num_edges))\n",
    "    random.shuffle(edge_ids)\n",
    "    num_remove = int(num_edges * prob)\n",
    "    edges_to_remove = edge_ids[:num_remove]\n",
    "    return dgl.remove_edges(dgl_graph, edges_to_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgl_graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, idx = plt.subplots(3, 3, figsize=(12, 12))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axis = idx[i, j]\n",
    "        sample = train_set[random.randint(0, len(train_set))]\n",
    "        dgl_graph = random_remove_edges(read_letter(sample, self_loops = False), prob=0.4)\n",
    "        G = dgl.to_networkx(dgl_graph)\n",
    "        features = {node_id:row for node_id, row in enumerate(dgl_graph.ndata[\"feat\"].numpy())}\n",
    "        plot_graph(G, features, axis)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#draw_strokes(sample)\n",
    "#webbrowser.open(r\"D:\\NIL\\OMNIGLOT\\sample.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide in train, test, validation.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate(graphs):\n",
    "    labels = list(map(lambda x: x.adj(), graphs))\n",
    "    removed_edges = list(map(random_remove_edges, graphs))\n",
    "    batched_graph = dgl.batch(removed_edges)\n",
    "    return batched_graph, labels\n",
    "\n",
    "trainset, validset, testset = read_npz_files(filename)\n",
    "\n",
    "Train_Graphs = [read_letter(graph, self_loops=True) for graph in trainset]\n",
    "Valid_Graphs = [read_letter(graph, self_loops=True) for graph in validset]\n",
    "Test_Graphs  = [read_letter(graph, self_loops=True) for graph in testset]\n",
    "\n",
    "# Define the three dataloaders. Train data will be shuffled at each epoch\n",
    "train_loader = DataLoader(Train_Graphs, batch_size=1, shuffle=True,\n",
    "                         collate_fn=collate)\n",
    "valid_loader = DataLoader(Valid_Graphs, batch_size=1, collate_fn=collate)\n",
    "test_loader = DataLoader(Test_Graphs, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide in train, test, validation.\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate(graphs):\n",
    "    print(graphs)\n",
    "    labels = list(map(lambda x: x.adj(), graphs))\n",
    "    removed_edges = list(map(random_remove_edges, graphs))\n",
    "    batched_graph = dgl.batch(removed_edges)\n",
    "    return batched_graph, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset, testset = read_npz_files(filename)\n",
    "Train_Graphs = [read_letter(graph) for graph in trainset[:10]]\n",
    "Valid_Graphs = [read_letter(graph) for graph in validset[:10]]\n",
    "Test_Graphs  = [read_letter(graph) for graph in testset[:10]]\n",
    "\n",
    "train_loader = DataLoader(Train_Graphs, batch_size=32, shuffle=True,\n",
    "                     collate_fn=collate)\n",
    "val_loader = DataLoader(Valid_Graphs, batch_size=32, collate_fn=collate)\n",
    "test_loader  = DataLoader(Test_Graphs, batch_size=32, collate_fn=collate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VGAE import VGAE\n",
    "from Data_Loaders import loaders\n",
    "from pathlib import Path\n",
    "BASE_DIR = Path(\"/home/nbiescas/Desktop/CVC/CVC_internship\") #or Path().absolute()\n",
    "DATA_PATH = BASE_DIR / \"omniglot.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(2, 10).double()\n",
    "train_loader, val_loader, test_loader = loaders(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, _ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_edges = 0\n",
    "for graph, _ in train_loader:\n",
    "    total_edges += graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 0, 1], [0, 0, 1]])\n",
    "b = torch.tensor([[1, 0, 1], [0, 0, 1]])\n",
    "torch.sum(a == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, adjacenc = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(graph, graph.ndata['feat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(train_loader, val_loader, model)\n",
      "File \u001b[0;32m~/Desktop/CVC/CVC_internship/training.py:44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, val_loader, model)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39m#if torch.cuda.is_available():\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m#    sparse_adj = sparse_adj.cuda()\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m#    graph = graph.to(sparse_adj.device)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m features \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mndata\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m---> 44\u001b[0m logits, model_mean, model_log_var \u001b[39m=\u001b[39m model(graph, features)\n\u001b[1;32m     45\u001b[0m loss \u001b[39m=\u001b[39m loss_VGAE(logits, sparse_adj, model_mean, model_log_var)\n\u001b[1;32m     46\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/CVC/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/CVC/CVC_internship/models/VGAE.py:57\u001b[0m, in \u001b[0;36mVGAE.forward\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, graph, feat):\n\u001b[0;32m---> 57\u001b[0m     mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(graph, feat) \u001b[39m#Returns two torch.tensors representing the mean and the log variance\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparametrize(mu, logvar)\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(z), mu, logvar\n",
      "File \u001b[0;32m~/Desktop/CVC/CVC_internship/models/VGAE.py:35\u001b[0m, in \u001b[0;36mVGAE.encode\u001b[0;34m(self, graph, feat)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, graph, feat):\n\u001b[0;32m---> 35\u001b[0m     h1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mGCN(graph, feat)\n\u001b[1;32m     36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_GCN(graph, h1), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstd_GCN(graph, h1)\n",
      "File \u001b[0;32m~/miniconda3/envs/CVC/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/CVC/lib/python3.11/site-packages/dgl/nn/pytorch/conv/graphconv.py:460\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    458\u001b[0m     rst \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mdstdata[\u001b[39m\"\u001b[39m\u001b[39mh\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    459\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 460\u001b[0m         rst \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mmatmul(rst, weight)\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    463\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39min_degrees()\u001b[39m.\u001b[39mto(feat_dst)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "train(train_loader, val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1., 1., 1., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 1., 0., 1.],\n",
       "         [1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [1., 1., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [0., 1., 1., 0., 0., 0., 1., 0., 1.],\n",
       "         [1., 0., 0., 1., 1., 1., 0., 1., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 1., 0., 1.]], dtype=torch.float64,\n",
       "        grad_fn=<SigmoidBackward0>),\n",
       " tensor([[ -28.2817,  -23.6174,  -56.5341,   32.1436,   93.1186,  -60.2646,\n",
       "            -3.8599,   34.5649,   21.1156,   28.5343],\n",
       "         [ -59.9945,  -50.1001, -119.9269,   68.1869,  197.5345, -127.8404,\n",
       "            -8.1882,   73.3232,   44.7930,   60.5305],\n",
       "         [  -6.3851,  -38.4946,  -25.0240,    4.4134,    3.8723,  -16.2399,\n",
       "             0.6061,   30.0871,   24.2464,  -43.6818],\n",
       "         [ -16.4867,  -90.5485,  -61.3426,   12.1542,   14.5739,  -41.2296,\n",
       "             1.1709,   71.7420,   57.4091,  -99.4173],\n",
       "         [ -16.7154, -110.4360,  -69.0817,   10.7252,    5.1404,  -43.2814,\n",
       "             2.0173,   85.2565,   69.1492, -128.9571],\n",
       "         [ -15.9572, -108.0361,  -66.9129,   10.0149,    3.5576,  -41.5254,\n",
       "             2.0421,   83.1427,   67.5454, -127.0518],\n",
       "         [ -40.6461,  -66.9471,  -93.4520,   43.3663,  116.7598,  -89.2330,\n",
       "            -4.0769,   71.8534,   49.7334,   -8.8758],\n",
       "         [ -54.7203,  -96.5010, -128.1669,   57.8360,  153.8936, -120.6372,\n",
       "            -5.2046,  101.0156,   70.6974,  -21.5812],\n",
       "         [ -30.2017,  -69.7242,  -76.8253,   30.5098,   76.4244,  -67.8908,\n",
       "            -2.1391,   66.8154,   48.6897,  -36.7937]], dtype=torch.float64,\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[1.9502e+20, 7.7072e-29, 6.9000e-09, 3.3315e+19, 8.5119e+38, 7.7562e-29,\n",
       "          1.0549e+21, 7.4863e-14, 1.8101e+25, 3.8783e+18],\n",
       "         [1.1010e+43, 2.3073e-60, 4.8706e-18, 2.5928e+41, 3.8288e+82, 2.3385e-60,\n",
       "          3.9534e+44, 1.4326e-28, 3.7989e+53, 2.7068e+39],\n",
       "         [6.6133e-01, 6.2475e-10, 6.7230e-21, 7.2326e-07, 1.5605e-08, 7.6971e-10,\n",
       "          4.5741e-09, 3.3459e-16, 1.0581e+16, 2.5799e-15],\n",
       "         [6.4011e+00, 9.9132e-24, 6.3602e-48, 9.0848e-14, 1.8614e-16, 1.6076e-23,\n",
       "          9.0656e-19, 2.3947e-37, 4.1936e+38, 2.2040e-33],\n",
       "         [1.3897e-02, 1.1799e-25, 7.0897e-59, 7.0983e-20, 5.3423e-26, 2.1641e-25,\n",
       "          2.2651e-26, 6.9449e-45, 9.0691e+44, 2.1694e-44],\n",
       "         [7.1212e-03, 9.5010e-25, 1.1115e-57, 7.7568e-20, 3.6993e-26, 1.7232e-24,\n",
       "          3.0802e-26, 7.2466e-44, 5.3765e+43, 6.8978e-44],\n",
       "         [2.6480e+24, 5.6567e-44, 1.0675e-30, 3.6281e+17, 2.7100e+39, 7.0159e-44,\n",
       "          1.5510e+17, 4.8236e-32, 3.7410e+46, 1.0466e+08],\n",
       "         [9.2229e+31, 1.6925e-59, 1.3426e-44, 4.1013e+21, 7.9062e+49, 2.3537e-59,\n",
       "          4.2500e+20, 2.7241e-45, 4.8195e+64, 1.5378e+07],\n",
       "         [1.9019e+15, 1.3929e-34, 4.8578e-34, 4.9255e+06, 2.0029e+19, 1.8520e-34,\n",
       "          7.7494e+04, 1.5565e-31, 6.6762e+40, 4.3793e-06]], dtype=torch.float64,\n",
       "        grad_fn=<ExpBackward0>))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(graph, features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
