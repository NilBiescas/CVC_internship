
Train Epoch: 0 	Graphs_seen: 0.0% 	Loss: 218.541016
Train Epoch: 0 	Graphs_seen: 27.23% 	Loss: 217.849594
Train Epoch: 0 	Graphs_seen: 54.47% 	Loss: 215.109497
Train Epoch: 0 	Graphs_seen: 81.7% 	Loss: 215.871201
Train Epoch: 0 	Graphs_seen: 108.94% 	Loss: 213.112595
Test set: Average loss: 1.6621, Accuracy: 10722.0/2012400856.0 (0%)
Train Epoch: 1 	Graphs_seen: 0.0% 	Loss: 213.911133
Train Epoch: 1 	Graphs_seen: 27.23% 	Loss: 219.345184
Train Epoch: 1 	Graphs_seen: 54.47% 	Loss: 211.395721
Train Epoch: 1 	Graphs_seen: 81.7% 	Loss: 207.266739
Train Epoch: 1 	Graphs_seen: 108.94% 	Loss: 208.993912
Test set: Average loss: 1.6320, Accuracy: 10719.0/2012400856.0 (0%)
Train Epoch: 2 	Graphs_seen: 0.0% 	Loss: 209.524475
Train Epoch: 2 	Graphs_seen: 27.23% 	Loss: 207.884766
Train Epoch: 2 	Graphs_seen: 54.47% 	Loss: 209.563522
Traceback (most recent call last):
  File "/home/nbiescas/Desktop/CVC/CVC_internship/main.py", line 29, in <module>
    model_pipeline(model, train_loader, val_loader, test_loader)
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 98, in model_pipeline
    for epoch in tqdm(range(80):
                     ^^^^^^^^^^^^
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 74, in train
    output, means_list, log_std_list = model(graph, features)  #The output is a list containing the different predictions for the graphs
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/nbiescas/Desktop/CVC/CVC_internship/training.py", line 22, in loss_VGAE
    kl_divergence = 0.5 / pred.size(0) * (
                                          ^
KeyboardInterrupt